{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import custom_model\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((2048, 1024)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Get the data\n",
    "all_data = []\n",
    "folder_paths=[r\"D:\\Unity\\AITX_PanLoc\\Assets\\data\\21.34938_-12.25565_folder\"]\n",
    "for folder_path in folder_paths:\n",
    "    file_paths = os.listdir(folder_path)\n",
    "\n",
    "    base_image = next((os.path.join(folder_path, f) for f in file_paths if \"_1.\" in f and f.endswith(\".jpg\")), None)\n",
    "    base_text = next((os.path.join(folder_path, f) for f in file_paths if \"_1.\" in f and f.endswith(\".txt\")), None)\n",
    "\n",
    "    if not (base_image and base_text):\n",
    "        print(f\"Base image or text not found in {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    with open(base_text, 'r') as f:\n",
    "        base_position = [float(x) for x in f.read().split(\"(\")[1].split(\")\")[0].split(\",\")]\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        if \"_1.\" in file_path or not file_path.endswith(\".jpg\"):\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(folder_path, file_path)\n",
    "        txt_path = os.path.join(folder_path, f\"{os.path.splitext(file_path)[0]}.txt\")\n",
    "\n",
    "        if os.path.exists(txt_path):\n",
    "            with open(txt_path, 'r') as f:\n",
    "                location = [float(x) for x in f.read().split(\"(\")[1].split(\")\")[0].split(\",\")]\n",
    "            relative_x = location[0] - base_position[0]\n",
    "            relative_y = location[2] - base_position[2]\n",
    "            \n",
    "            max_distance = 50\n",
    "            normalized_x = np.clip(relative_x / max_distance, -1, 1)\n",
    "            normalized_y = np.clip(relative_y / max_distance, -1, 1)\n",
    "            \n",
    "            all_data.append((base_image, image_path, normalized_x, normalized_y, 1.0))\n",
    "\n",
    "# Turn the paths into tensors of the image\n",
    "for i, data in enumerate(all_data):\n",
    "    base_image=Image.open(data[0])\n",
    "    base_image=transform(base_image).unsqueeze(0)\n",
    "    current_image=Image.open(data[1])\n",
    "    current_image=transform(current_image).unsqueeze(0)\n",
    "    position=(data[2], data[4])\n",
    "    all_data[i]=(base_image, current_image, position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePairDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        base_img, current_img, position = self.data[idx]\n",
    "        return base_img.squeeze(0), current_img.squeeze(0), torch.tensor(position)\n",
    "\n",
    "dataset = ImagePairDataset(all_data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_model.ImagePositionPredictor()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(pred, target):\n",
    "    # convert everything to float\n",
    "    pred = pred.float()\n",
    "    target = target.float()\n",
    "    mse_loss = F.mse_loss(pred[:, :1], target[:, :1])\n",
    "    # bce_loss = F.binary_cross_entropy(pred[:, 1], target[:, 1])\n",
    "    return mse_loss#+ bce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0273,  0.0559],\n",
      "        [-0.0430,  0.0506],\n",
      "        [-0.0451,  0.0522]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.8784,  1.0000],\n",
      "        [ 0.1934,  1.0000],\n",
      "        [-0.6916,  1.0000]], device='cuda:0', dtype=torch.float64)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "Epoch 1/3, Loss: 0.3994\n",
      "tensor([[-0.3911, -0.0596],\n",
      "        [-0.3612, -0.0597],\n",
      "        [-0.3533, -0.0577]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.8784,  1.0000],\n",
      "        [ 0.1934,  1.0000],\n",
      "        [-0.6916,  1.0000]], device='cuda:0', dtype=torch.float64)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "Epoch 2/3, Loss: 0.2199\n",
      "tensor([[-0.5921, -0.1350],\n",
      "        [-0.6048, -0.1373],\n",
      "        [-0.6552, -0.1501]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.6916,  1.0000],\n",
      "        [ 0.1934,  1.0000],\n",
      "        [-0.8784,  1.0000]], device='cuda:0', dtype=torch.float64)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "Epoch 3/3, Loss: 0.2323\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for base_img, current_img, position in dataloader:\n",
    "        base_img, current_img, position = base_img.to(device), current_img.to(device), position.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(base_img, current_img)\n",
    "        loss = custom_loss(output, position)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    scheduler.step(avg_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
